{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6b729ae",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f187fa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import dateutil\n",
    "from pymongo import MongoClient\n",
    "import re\n",
    "from bson import json_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce8e36c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient('localhost', 27017)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953ac630",
   "metadata": {},
   "source": [
    "if you have alrd loaded ur dataset, then can just rename the params in\n",
    "\n",
    "client[] and mydb[] so that it matches urs\n",
    "\n",
    "then no need to load the data again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70c481d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = client[\"amazonPhones\"]\n",
    "my_collection = mydb[\"phonesNaccessories\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8bd8991",
   "metadata": {},
   "outputs": [],
   "source": [
    "### if you want to clear collection in DB use and uncomment this\n",
    "# my_collection.delete_many({})\n",
    "\n",
    "\n",
    "#### --- LOADING DATA INTO DB ---\n",
    "#### Uncomment this if u want to load data into db\n",
    "\n",
    "## the file is written to the String contents\n",
    "#jsonDataSetString = open(\"Cell_Phones_and_Accessories.json\", \"r\").read()\n",
    "\n",
    "## load String into a dict, parse by each line\n",
    "#jsonDataSetDict = [json.loads(str(item)) for item in jsonDataSetString.strip().split('\\)\n",
    "#my_collection.insert_many(jsonDataSetDict)\n",
    "\n",
    "\n",
    "#### ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2490136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "{'_id': ObjectId('63e8d766e624f638f68b47ed'), 'category': ['Cell Phones & Accessories', 'Accessories', 'Screen Protectors'], 'tech1': '', 'description': [], 'fit': '', 'title': 'Trollies Sing a Long Party VHS', 'also_buy': [], 'tech2': '', 'brand': '', 'feature': [], 'rank': '557,379 in Movies & TV (', 'also_view': [], 'details': {'ASIN: ': '6303195164'}, 'main_cat': 'Movies & TV', 'similar_item': '', 'date': '', 'price': '', 'asin': '6303195164', 'imageURL': [], 'imageURLHighRes': []}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "bson.objectid.ObjectId"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test to see if some data is inserted\n",
    "exampleTest = my_collection.find_one()\n",
    "print(type(exampleTest))\n",
    "print(exampleTest)\n",
    "type(exampleTest['_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73ae56a",
   "metadata": {},
   "source": [
    "Edit `limitQ` to change sample size\n",
    "\n",
    "`q6` query has been removed to keep the mongoDB-specific ID object\n",
    "However this necessitates the use of the `bson` package's `json_util.default` to encode the ID object into json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b941aa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate Queries\n",
    "## Remove all irrelevant fields\n",
    "q0 = {\"$unset\" : [\"fit\",\"tech1\",\"tech2\",\"imageURL\",\"imageURLHighRes\"]}\n",
    "\n",
    "## Match all documents that have \"Cell Phones\" string in category field\n",
    "q1 = {\"$match\" :{ \"category\": { \"$in\": [\"Cell Phones\"] } } }\n",
    "\n",
    "## Match all documents that have some sort of ranking in the general Cell Phones & Accessories\n",
    "regexQ2 = re.compile(\"^>#.* in Cell Phones & Accessories \\(See Top 100 in Cell Phones & Accessories\\)\")\n",
    "q2 = {\"$match\": { \"rank\": { \"$elemMatch\": {\"$regex\": regexQ2 } } } }\n",
    "\n",
    "## Add a new field ranking the documents based on the \"rank\" string. Removes all hashtags and commas.\n",
    "regexQ3 = re.compile(\"[#,]\")\n",
    "q3 = {\"$addFields\": {\"overallRankRemovedHash\": {\"$replaceAll\": {\"input\": {\"$arrayElemAt\": [\"$rank\", 0]} , \"find\": \"#\", \"replacement\": \"\"}}}}\n",
    "\n",
    "q3p1 = {\"$addFields\": {\"overallRankRemovedRightArrow\": {\"$replaceAll\": {\"input\": \"$overallRankRemovedHash\", \"find\": \">\", \"replacement\" : \"\"}}}}\n",
    "q3p2 = {\"$addFields\": {\"overallRankRemovedComma\": {\"$replaceAll\": {\"input\": \"$overallRankRemovedRightArrow\", \"find\": \",\", \"replacement\": \"\"}}}}\n",
    "\n",
    "## Now split by whitespace and only select first element (which is the number rank)\n",
    "q4 = {\"$addFields\": {\"overallRankNumber\": {\"$toInt\": {\"$arrayElemAt\": [{\"$split\": [\"$overallRankRemovedComma\", \" \"]}, 0] } } } }\n",
    "\n",
    "## remove the intermediate \"rankRemovedHashComma\" (and also _id actually)\n",
    "q5 = {\"$unset\" : [\"overallRankRemovedHash\", \"overallRankRemovedRightArrow\", \"overallRankRemovedComma\", 'also_view', \"also_buy\", \"main_cat\", \"rank\", \"similar_item\"]}\n",
    "\n",
    "q6 = {\"$unset\" : \"_id\"}\n",
    "\n",
    "limitQ = {\"$limit\" : 10}\n",
    "\n",
    "## sort by rank ascending\n",
    "sortQ = {\"$sort\" : {\"overallRankNumber\" : 1}}\n",
    "\n",
    "# pipeline\n",
    "aggPipe = [q0, q1, q2, q3, q3p1, q3p2, q4, q5, sortQ, limitQ]\n",
    "\n",
    "# processing thru pipeline\n",
    "commandCursor = my_collection.aggregate(aggPipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab918ef4",
   "metadata": {},
   "source": [
    "## Loading cleaned data into `documents` list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7a0a566",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = []\n",
    "for document in commandCursor:\n",
    "    documents.append(document)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2387f8",
   "metadata": {},
   "source": [
    "## Exporting data into output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "549b3514",
   "metadata": {},
   "outputs": [],
   "source": [
    "documentsJsonString = json.dumps(documents, default=json_util.default)\n",
    "# # write list of dicts to file\n",
    "with open('outputSample10.json', 'w') as outfile:\n",
    "    outfile.write(documentsJsonString)\n",
    "\n",
    "\n",
    "# with open('outputSample10.json', 'w') as outfile:\n",
    "#     json.dump(documents, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ec2ef2",
   "metadata": {},
   "source": [
    "*Ignore panel below, will figure out how to import into mongoDB through pymongo*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b220a67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### --- LOADING DATA INTO DB ---\n",
    "#### Uncomment this if u want to load data into db\n",
    "\n",
    "## the file is written to the String contents\n",
    "##jsonDataSetString = open(\".json\", \"r\").read()\n",
    "\n",
    "## load String into a dict, parse by each line\n",
    "#jsonDataSetDict = [json.loads(str(item)) for item in jsonDataSetString.strip().split('\\')\n",
    "#my_collection.insert_many(jsonDataSetDict)\n",
    "\n",
    "\n",
    "#### ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c6ad15",
   "metadata": {},
   "source": [
    "## Generating JoinedSample of 10\n",
    "\n",
    "First import the cleaned metadata sample of 10 into MongoDB as `cleanedMetadataSample10` collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e7a9454b",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_metadata_sample_collection = mydb[\"cleanedMetadataSample10\"]\n",
    "\n",
    "joinQ = {\"$lookup\": {\"from\": \"phonesNaccessoriesReviews\",\"localField\": \"asin\",\"foreignField\": \"asin\",\"as\": \"review\"}}\n",
    "\n",
    "joinAggPipe = [joinQ]\n",
    "commandCursorJoined = cleaned_metadata_sample_collection.aggregate(joinAggPipe)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "964957e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "documentsJoined = []\n",
    "for document in commandCursorJoined:\n",
    "    documentsJoined.append(document)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f5feb540",
   "metadata": {},
   "outputs": [],
   "source": [
    "documentsJsonString = json.dumps(documentsJoined, default=json_util.default)\n",
    "# # write list of dicts to file\n",
    "with open('outputJoinedSample10.json', 'w') as outfile:\n",
    "    outfile.write(documentsJsonString)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ac5ea931",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type ObjectId is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_18612\\1618327246.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'outputJoinedSample10.json'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0moutfile\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocumentsJoined\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mdump\u001b[1;34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[0m\n\u001b[0;32m    177\u001b[0m     \u001b[1;31m# could accelerate with writelines in some versions of Python, at\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;31m# a debuggability cost\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m         \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[1;34m(o, _current_indent_level)\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0m_floatstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m_iterencode_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m_iterencode_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36m_iterencode_list\u001b[1;34m(lst, _current_indent_level)\u001b[0m\n\u001b[0;32m    323\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 325\u001b[1;33m                 \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36m_iterencode_dict\u001b[1;34m(dct, _current_indent_level)\u001b[0m\n\u001b[0;32m    403\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m                     \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 405\u001b[1;33m                 \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mchunks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    406\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnewline_indent\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    407\u001b[0m             \u001b[0m_current_indent_level\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36m_iterencode\u001b[1;34m(o, _current_indent_level)\u001b[0m\n\u001b[0;32m    436\u001b[0m                     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Circular reference detected\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    437\u001b[0m                 \u001b[0mmarkers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mmarkerid\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 438\u001b[1;33m             \u001b[0mo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    439\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m_iterencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_current_indent_level\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mmarkers\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\json\\encoder.py\u001b[0m in \u001b[0;36mdefault\u001b[1;34m(self, o)\u001b[0m\n\u001b[0;32m    177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m         \"\"\"\n\u001b[1;32m--> 179\u001b[1;33m         raise TypeError(f'Object of type {o.__class__.__name__} '\n\u001b[0m\u001b[0;32m    180\u001b[0m                         f'is not JSON serializable')\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: Object of type ObjectId is not JSON serializable"
     ]
    }
   ],
   "source": [
    "# with open('outputJoinedSample10.json', 'w') as outfile:\n",
    "#     json.dump(documentsJoined, outfile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
